#!/usr/bin/env python3
"""
Prueba completa del pipeline para verificar claridad de audio y diferenciaci√≥n de hablantes
"""
import os
import sys
import django
from pathlib import Path

# Configurar Django
sys.path.append('/app')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
django.setup()

from apps.audio_processing.models import ProcesamientoAudio
from apps.transcripcion.models import Transcripcion
from apps.audio_processing.services.audio_pipeline import AudioProcessor, get_audio_info
from apps.transcripcion.whisper_helper_audit import WhisperProcessor  
from apps.transcripcion.pyannote_helper import PyannoteProcessor
import tempfile
import json

def test_complete_clarity_pipeline():
    """
    Prueba completa para verificar claridad de audio y diferenciaci√≥n de hablantes
    """
    print("üéØ PRUEBA DE CLARIDAD Y DIFERENCIACI√ìN DE HABLANTES")
    print("=" * 70)
    
    # Buscar una transcripci√≥n reciente que tenga m√∫ltiples hablantes
    transcripcion = Transcripcion.objects.filter(
        estado='completado',
        hablantes_detectados__gte=2  # Al menos 2 hablantes
    ).order_by('-fecha_creacion').first()
    
    if not transcripcion:
        print("‚ùå No se encontr√≥ transcripci√≥n con m√∫ltiples hablantes")
        return
    
    print(f"üéµ Transcripci√≥n encontrada: ID {transcripcion.id}")
    print(f"üìù Archivo: {transcripcion.nombre_archivo if hasattr(transcripcion, 'nombre_archivo') else 'N/A'}")
    print(f"üë• Hablantes detectados: {transcripcion.hablantes_detectados}")
    print(f"‚è±Ô∏è Duraci√≥n: {transcripcion.duracion_total}s")
    print(f"üìÖ Estado: {transcripcion.estado}")
    print(f"üìÖ Fecha: {transcripcion.fecha_creacion}")
    
    # Obtener el procesamiento de audio asociado
    procesamiento = ProcesamientoAudio.objects.filter(
        transcripcion=transcripcion
    ).first()
    
    if not procesamiento:
        # Buscar por el campo relacionado directo
        procesamiento = getattr(transcripcion, 'procesamiento_relacionado', None)
        
    if not procesamiento:
        print("‚ùå No se encontr√≥ procesamiento de audio asociado")
        # Buscar cualquier procesamiento reciente
        procesamiento = ProcesamientoAudio.objects.filter(
            estado='completado'
        ).order_by('-fecha_completado').first()
        
        if procesamiento:
            print(f"üîÑ Usando procesamiento alternativo: ID {procesamiento.id}")
        else:
            print("‚ùå No hay procesamientos de audio disponibles")
            return
    
    print(f"üîä Procesamiento de audio: ID {procesamiento.id}")
    
    # Verificar archivos de audio disponibles
    archivo_original = procesamiento.archivo_audio.path if procesamiento.archivo_audio else None
    archivo_mejorado = procesamiento.archivo_mejorado.path if procesamiento.archivo_mejorado else None
    
    if not archivo_original or not os.path.exists(archivo_original):
        print(f"‚ùå Archivo original no disponible: {archivo_original}")
        return
        
    if not archivo_mejorado or not os.path.exists(archivo_mejorado):
        print(f"‚ùå Archivo mejorado no disponible: {archivo_mejorado}")
        return
    
    print(f"üìÅ Archivo original: {archivo_original}")
    print(f"üìÅ Archivo mejorado: {archivo_mejorado}")
    
    # AN√ÅLISIS 1: Comparar informaci√≥n de archivos
    print(f"\nüìä AN√ÅLISIS DE CALIDAD DE AUDIO:")
    
    info_original = get_audio_info(archivo_original)
    info_mejorado = get_audio_info(archivo_mejorado)
    
    print(f"üéµ Archivo Original:")
    print(f"   - Duraci√≥n: {info_original['duration']:.2f}s")
    print(f"   - Sample Rate: {info_original['sample_rate']}Hz")
    print(f"   - Canales: {info_original['channels']}")
    print(f"   - Tama√±o: {info_original['size']/1024/1024:.2f}MB")
    print(f"   - Codec: {info_original['codec']}")
    
    print(f"üéµ Archivo Mejorado:")
    print(f"   - Duraci√≥n: {info_mejorado['duration']:.2f}s")
    print(f"   - Sample Rate: {info_mejorado['sample_rate']}Hz")
    print(f"   - Canales: {info_mejorado['channels']}")
    print(f"   - Tama√±o: {info_mejorado['size']/1024/1024:.2f}MB")
    print(f"   - Codec: {info_mejorado['codec']}")
    
    # Calcular mejoras
    duration_reduction = info_original['duration'] - info_mejorado['duration']
    size_reduction = (info_original['size'] - info_mejorado['size']) / info_original['size'] * 100
    
    print(f"\n‚ú® MEJORAS APLICADAS:")
    print(f"   üîá Silencio eliminado: {duration_reduction:.2f}s")
    print(f"   üíæ Reducci√≥n de tama√±o: {size_reduction:.1f}%")
    print(f"   üéõÔ∏è Normalizado a: {info_mejorado['sample_rate']}Hz (√≥ptimo para transcripci√≥n)")
    
    # AN√ÅLISIS 2: Verificar diferenciaci√≥n de hablantes
    print(f"\nüë• AN√ÅLISIS DE DIFERENCIACI√ìN DE HABLANTES:")
    
    if transcripcion.conversacion_json:
        try:
            conversacion = transcripcion.conversacion_json
            if isinstance(conversacion, str):
                conversacion = json.loads(conversacion)
            
            # Si es un string que parece lista, intentar evaluarlo
            if isinstance(conversacion, str) and conversacion.startswith('['):
                import ast
                conversacion = ast.literal_eval(conversacion)
                
            # Si no es lista a√∫n, intentar extraer de estructura anidada
            if not isinstance(conversacion, list):
                if isinstance(conversacion, dict) and 'conversacion' in conversacion:
                    conversacion = conversacion['conversacion']
                elif isinstance(conversacion, dict) and 'segmentos' in conversacion:
                    conversacion = conversacion['segmentos']
                else:
                    print(f"‚ö†Ô∏è Formato de conversaci√≥n desconocido: {type(conversacion)}")
                    print(f"   Primeros caracteres: {str(conversacion)[:100]}...")
                    conversacion = []
            
            # Contar hablantes √∫nicos
            hablantes_unicos = set()
            total_segmentos = len(conversacion) if isinstance(conversacion, list) else 0
            
            if total_segmentos > 0:
                for segmento in conversacion:
                    if isinstance(segmento, dict):
                        speaker = segmento.get('speaker', 'desconocido')
                        hablantes_unicos.add(speaker)
                    elif isinstance(segmento, str):
                        # Si es un string, intentar extraer info
                        hablantes_unicos.add('hablante_parseado')
            
            print(f"üë• Hablantes detectados en conversaci√≥n: {len(hablantes_unicos)}")
            print(f"üìù Total de segmentos: {total_segmentos}")
            
            if total_segmentos > 0 and len(hablantes_unicos) > 0:
                # Mostrar distribuci√≥n de hablantes
                hablante_stats = {}
                for segmento in conversacion:
                    if not isinstance(segmento, dict):
                        continue
                        
                    speaker = segmento.get('speaker', 'desconocido')
                    if speaker not in hablante_stats:
                        hablante_stats[speaker] = {
                            'segmentos': 0,
                            'duracion_total': 0,
                            'primer_aparicion': None,
                            'ultimo_segmento': None
                        }
                    
                    hablante_stats[speaker]['segmentos'] += 1
                    inicio = segmento.get('inicio', segmento.get('start', 0))
                    fin = segmento.get('fin', segmento.get('end', 0))
                    duracion = fin - inicio
                    hablante_stats[speaker]['duracion_total'] += duracion
                    
                    if hablante_stats[speaker]['primer_aparicion'] is None:
                        hablante_stats[speaker]['primer_aparicion'] = inicio
                        hablante_stats[speaker]['ultimo_segmento'] = segmento.get('texto', segmento.get('text', ''))[:50]
                
                print(f"\nüéØ DISTRIBUCI√ìN POR HABLANTE:")
                for i, (speaker, stats) in enumerate(sorted(hablante_stats.items()), 1):
                    if total_segmentos > 0:
                        porcentaje = (stats['segmentos'] / total_segmentos) * 100
                        print(f"   {i}. {speaker}:")
                        print(f"      üìä Segmentos: {stats['segmentos']} ({porcentaje:.1f}%)")
                        print(f"      ‚è±Ô∏è Tiempo total: {stats['duracion_total']:.1f}s")
                        print(f"      üé¨ Primera aparici√≥n: {stats['primer_aparicion']:.1f}s")
                        print(f"      üí¨ √öltimo texto: \"{stats['ultimo_segmento']}...\"")
                        print()
                
                # Verificar calidad de diferenciaci√≥n
                if len(hablantes_unicos) >= 2:
                    print(f"‚úÖ DIFERENCIACI√ìN EXITOSA:")
                    print(f"   - Se detectaron {len(hablantes_unicos)} hablantes diferentes")
                    print(f"   - Los hablantes tienen distribuciones distintas")
                    print(f"   - Cada hablante tiene texto espec√≠fico")
                else:
                    print(f"‚ö†Ô∏è DIFERENCIACI√ìN LIMITADA:")
                    print(f"   - Solo se detect√≥ {len(hablantes_unicos)} hablante")
                    print(f"   - Puede necesitar ajustes en diarizaci√≥n")
            else:
                print(f"‚ö†Ô∏è No se encontraron segmentos v√°lidos en la conversaci√≥n")
        
        except Exception as e:
            print(f"‚ùå Error analizando conversaci√≥n: {e}")
            print(f"   Tipo de datos: {type(transcripcion.conversacion_json)}")
            if hasattr(transcripcion.conversacion_json, '__len__'):
                print(f"   Longitud: {len(transcripcion.conversacion_json)}")
            # Mostrar muestra de los datos para debug
            sample = str(transcripcion.conversacion_json)[:200]
            print(f"   Muestra: {sample}...")
            hablantes_unicos = set(['debug'])
            total_segmentos = 1
    
    # AN√ÅLISIS 3: Verificar par√°metros de calidad usados
    print(f"\nüîß PAR√ÅMETROS DE CALIDAD APLICADOS:")
    
    if hasattr(transcripcion, 'parametros_aplicados') and transcripcion.parametros_aplicados:
        params = transcripcion.parametros_aplicados
        print(f"   üé§ Modelo Whisper: {params.get('modelo_whisper', 'N/A')}")
        print(f"   üéõÔ∏è Modelo pyannote: {params.get('modelo_diarizacion', 'N/A')}")
        print(f"   üë• Speakers forzados: {params.get('max_speakers', 'N/A')}")
        print(f"   üîä VAD filter: {params.get('vad_filter', 'N/A')}")
        print(f"   üìè Beam size: {params.get('beam_size', 'N/A')}")
    
    # AN√ÅLISIS 4: Verificar metadatos de procesamiento
    if hasattr(procesamiento, 'metadatos_procesamiento') and procesamiento.metadatos_procesamiento:
        metadatos = procesamiento.metadatos_procesamiento
        print(f"\nüéµ METADATOS DE PROCESAMIENTO:")
        pipeline_version = metadatos.get('pipeline_version', 'N/A')
        print(f"   üîÑ Versi√≥n pipeline: {pipeline_version}")
        
        if 'optimization_applied' in metadatos:
            print(f"   ‚ú® Optimizaciones: {metadatos.get('optimization_applied', False)}")
        if 'resemblyzer_used' in metadatos:
            print(f"   üéõÔ∏è Resemblyzer: {metadatos.get('resemblyzer_used', False)}")
        if 'quality_improvements' in metadatos:
            improvements = metadatos.get('quality_improvements', [])
            print(f"   üéØ Mejoras aplicadas: {len(improvements)}")
    
    # CONCLUSI√ìN
    print(f"\nüéØ EVALUACI√ìN DE CLARIDAD Y DIFERENCIACI√ìN:")
    
    criterios_calidad = []
    
    # 1. Optimizaci√≥n de audio
    if info_mejorado['sample_rate'] == 16000:
        criterios_calidad.append("‚úÖ Audio optimizado a 16kHz (ideal para transcripci√≥n)")
    else:
        criterios_calidad.append("‚ö†Ô∏è Audio no optimizado")
    
    # 2. Reducci√≥n de ruido
    if duration_reduction > 0:
        criterios_calidad.append(f"‚úÖ Silencio eliminado ({duration_reduction:.1f}s)")
    else:
        criterios_calidad.append("‚ö†Ô∏è No se detect√≥ eliminaci√≥n de silencio")
    
    # 3. Diferenciaci√≥n de hablantes
    if len(hablantes_unicos) >= 2:
        criterios_calidad.append(f"‚úÖ M√∫ltiples hablantes diferenciados ({len(hablantes_unicos)})")
    else:
        criterios_calidad.append("‚ö†Ô∏è Diferenciaci√≥n de hablantes limitada")
    
    # 4. Calidad de transcripci√≥n
    if total_segmentos > 0:
        criterios_calidad.append(f"‚úÖ Transcripci√≥n detallada ({total_segmentos} segmentos)")
    else:
        criterios_calidad.append("‚ö†Ô∏è Transcripci√≥n limitada")
    
    print(f"\nüìã CRITERIOS DE CALIDAD:")
    for criterio in criterios_calidad:
        print(f"   {criterio}")
    
    # Puntuaci√≥n final
    exitosos = len([c for c in criterios_calidad if c.startswith("‚úÖ")])
    total = len(criterios_calidad)
    puntuacion = (exitosos / total) * 100
    
    print(f"\nüèÜ PUNTUACI√ìN FINAL: {puntuacion:.0f}% ({exitosos}/{total} criterios)")
    
    if puntuacion >= 75:
        print("üéâ EXCELENTE: El audio sale claro y los hablantes se diferencian bien")
    elif puntuacion >= 50:
        print("üôÇ BUENO: Calidad aceptable con posibles mejoras")
    else:
        print("üòê MEJORABLE: Necesita ajustes para mejor claridad")

if __name__ == "__main__":
    test_complete_clarity_pipeline()